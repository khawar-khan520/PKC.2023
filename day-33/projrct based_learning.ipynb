{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Fashion MNIST dataset\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and test split of the Fashion MNIST dataset\n",
    "(training_images, training_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train),(X_test, y_test) = fashion_mnist.load_data()\n",
    "assert X_train.shape == (60000,28,28)\n",
    "assert X_test.shape == (10000,28,28)\n",
    "assert y_train.shape == (60000,)\n",
    "assert y_test.shape == (10000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : x(60000, 28, 28), y(60000,)\n",
      "test : x(10000, 28, 28), y(10000,)\n"
     ]
    }
   ],
   "source": [
    "#summaarize the loaded dataset\n",
    "print('train : x%s, y%s' % (X_train.shape,y_train.shape))\n",
    "print('test : x%s, y%s' % (X_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i in range(9):\n",
    "    #define yhe sub plot\n",
    "    plt.subplot(330+1+ i)\n",
    "    # plot raww data\n",
    "    plt.imshow(X_train[i], cmap= plt.get_cmap('gray'))\n",
    "    # show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255.0\n",
    "X_test= X_test /255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your model here or neural network \n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape = (28,28)),\n",
    "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu), # Try experimenting with this layer dense=64,128,512 and 1024 see difference\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train, epochs=5)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test,y_test)\n",
    "\n",
    "print('test accuraccy :' , test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 13s 14ms/step\n",
      "(10000, 10)\n",
      "[[1.79893887e-05 2.14363527e-09 1.43338525e-06 1.65829405e-07\n",
      "  1.40087536e-06 4.68859337e-02 1.67176258e-05 1.73018072e-02\n",
      "  2.28096796e-05 9.35751796e-01]\n",
      " [2.40219433e-05 1.57285244e-11 9.76913631e-01 5.04246565e-08\n",
      "  1.97074711e-02 5.75512103e-11 3.35493637e-03 6.86532570e-15\n",
      "  7.37614103e-09 9.93851455e-15]\n",
      " [4.39986499e-04 9.99447882e-01 2.70098972e-05 3.34763499e-05\n",
      "  5.07132499e-05 3.41463580e-10 5.56728082e-07 6.28430197e-09\n",
      "  3.56600339e-07 1.27031097e-09]\n",
      " [1.42534598e-04 9.98978853e-01 9.03741457e-05 7.49610772e-04\n",
      "  3.26395493e-05 7.13783921e-09 3.51965264e-06 8.19499633e-08\n",
      "  6.29924486e-08 2.41852126e-06]\n",
      " [2.14235410e-01 6.26919132e-07 1.61126349e-02 3.32265021e-03\n",
      "  6.95260847e-03 2.52384865e-07 7.59257793e-01 1.47635240e-06\n",
      "  1.16445553e-04 1.11167964e-07]\n",
      " [2.72767385e-03 9.96490300e-01 1.33133683e-04 3.14327976e-04\n",
      "  2.93242512e-04 1.00293125e-08 3.95618081e-05 1.38806735e-08\n",
      "  1.81462644e-06 3.22239413e-09]\n",
      " [1.43960788e-04 1.44861124e-05 1.24577163e-02 6.85499253e-05\n",
      "  9.77033019e-01 4.60447191e-05 1.00149885e-02 1.36622390e-07\n",
      "  2.21143258e-04 7.21332185e-08]\n",
      " [2.51739548e-04 6.04022148e-07 3.52908345e-03 4.70794912e-05\n",
      "  4.67455201e-02 1.08696995e-05 9.49351907e-01 2.75021875e-07\n",
      "  6.15870304e-05 1.46993750e-06]\n",
      " [1.69699790e-03 1.31395776e-04 3.74698022e-04 5.68615040e-04\n",
      "  3.51303643e-05 9.92415011e-01 4.59128321e-04 4.00370080e-03\n",
      "  2.64033384e-04 5.12606821e-05]\n",
      " [3.58294642e-06 9.14005156e-08 4.97852170e-07 2.24889945e-07\n",
      "  2.00003232e-08 5.47099020e-03 1.40783879e-06 9.94010508e-01\n",
      "  7.92068022e-05 4.33555833e-04]]\n",
      "[<tf.Tensor: shape=(), dtype=int64, numpy=9>, <tf.Tensor: shape=(), dtype=int64, numpy=2>, <tf.Tensor: shape=(), dtype=int64, numpy=1>, <tf.Tensor: shape=(), dtype=int64, numpy=1>, <tf.Tensor: shape=(), dtype=int64, numpy=6>, <tf.Tensor: shape=(), dtype=int64, numpy=1>, <tf.Tensor: shape=(), dtype=int64, numpy=4>, <tf.Tensor: shape=(), dtype=int64, numpy=6>, <tf.Tensor: shape=(), dtype=int64, numpy=5>, <tf.Tensor: shape=(), dtype=int64, numpy=7>]\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "predictions = model.predict(X_test)\n",
    "# print shape of predictions\n",
    "print(predictions.shape)\n",
    "# print 10 predictions\n",
    "print(predictions[:10])\n",
    "# convert predictions in labels\n",
    "class_labels = [tf.argmax(prediction) for prediction in predictions]\n",
    "# show first 10 labels\n",
    "print(class_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "source code string cannot contain null bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m (X_tain,y_train),(X_test,y_test) \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mfashion_mnist\u001b[39m.\u001b[39mload_data()\n\u001b[0;32m      6\u001b[0m X_train \u001b[39m=\u001b[39m X_train\u001b[39m/\u001b[39m\u001b[39m255.0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\khawar\\miniconda3\\envs\\tf_env\\lib\\site-packages\\matplotlib\\__init__.py:161\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpackaging\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m \u001b[39mimport\u001b[39;00m parse \u001b[39mas\u001b[39;00m parse_version\n\u001b[0;32m    159\u001b[0m \u001b[39m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[39m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[1;32m--> 161\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[0;32m    162\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcbook\u001b[39;00m \u001b[39mimport\u001b[39;00m sanitize_sequence\n\u001b[0;32m    163\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m \u001b[39mimport\u001b[39;00m MatplotlibDeprecationWarning\n",
      "File \u001b[1;32mc:\\Users\\khawar\\miniconda3\\envs\\tf_env\\lib\\site-packages\\matplotlib\\rcsetup.py:32\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_enums\u001b[39;00m \u001b[39mimport\u001b[39;00m JoinStyle, CapStyle\n\u001b[0;32m     31\u001b[0m \u001b[39m# Don't let the original cycler collide with our validating cycler\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcycler\u001b[39;00m \u001b[39mimport\u001b[39;00m Cycler, cycler \u001b[39mas\u001b[39;00m ccycler\n\u001b[0;32m     35\u001b[0m \u001b[39m# The capitalized forms are needed for ipython at present; this may\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39m# change for later versions.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m interactive_bk \u001b[39m=\u001b[39m [\n\u001b[0;32m     38\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mGTK3Agg\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mGTK3Cairo\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mGTK4Agg\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mGTK4Cairo\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     39\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mMacOSX\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mWX\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mWXAgg\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mWXCairo\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     45\u001b[0m ]\n",
      "\u001b[1;31mValueError\u001b[0m: source code string cannot contain null bytes"
     ]
    }
   ],
   "source": [
    "#gather all data and shows us with plots of loss and validation_val\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(X_tain,y_train),(X_test,y_test) = tf.keras.dataset.fashion_mnist.load_data()\n",
    "\n",
    "X_train = X_train/255.0\n",
    "X_test= X_test /255.0\n",
    "\n",
    "X_val=X_train [:5000]\n",
    "y_val = y_train[:5000]\n",
    "X_train =X_train[5000:]\n",
    "y_train =y_train[5000:]\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape = (28,28)),\n",
    "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu), # Try experimenting with this layer dense=64,128,512 and 1024 see difference\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "# train the model\n",
    "history = model.fit(X_train, y_train, epochs=5 , validation_data=(X_val,y_val))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test,y_test)\n",
    "\n",
    "plt.plot(history.history['loss'], label = 'training_loss')\n",
    "plt.plot(history.history['val_loss'], label = 'validation_loss')\n",
    "plt.x_label('epoch')\n",
    "plt.y_label('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "400ffac5c68edadfaf74af8d0857906cca696eb3532e6e22a4147460dc3f4aa3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
